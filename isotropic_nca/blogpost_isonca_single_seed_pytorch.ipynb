{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbyJuqANoinE"
      },
      "source": [
        "# Isotropic and Steerable NCA (Single seed experiments)\n",
        "\n",
        "*Copyright 2023 Google LLC*\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "you may not use this file except in compliance with the License.\n",
        "You may obtain a copy of the License at\n",
        "\n",
        "[https://www.apache.org/licenses/LICENSE-2.0](https://www.apache.org/licenses/LICENSE-2.0)\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software\n",
        "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "See the License for the specific language governing permissions and\n",
        "limitations under the License."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FR8YNR-g9JXA"
      },
      "outputs": [],
      "source": [
        "#@title Imports and Notebook Utilities\n",
        "\n",
        "import os\n",
        "import io\n",
        "import PIL.Image, PIL.ImageDraw\n",
        "import base64\n",
        "import zipfile\n",
        "import json\n",
        "import requests\n",
        "import numpy as np\n",
        "import matplotlib.pylab as pl\n",
        "import glob\n",
        "\n",
        "from IPython.display import Image, HTML, clear_output\n",
        "from tqdm import tqdm_notebook, tnrange\n",
        "\n",
        "os.environ['FFMPEG_BINARY'] = 'ffmpeg'\n",
        "import moviepy.editor as mvp\n",
        "from moviepy.video.io.ffmpeg_writer import FFMPEG_VideoWriter\n",
        "\n",
        "\n",
        "def imread(url, max_size=None, mode=None):\n",
        "  if url.startswith(('http:', 'https:')):\n",
        "    # wikimedia requires a user agent\n",
        "    headers = {\n",
        "      \"User-Agent\": \"Requests in Colab/0.0 (https://colab.research.google.com/; no-reply@google.com) requests/0.0\"\n",
        "    }\n",
        "    r = requests.get(url, headers=headers)\n",
        "    f = io.BytesIO(r.content)\n",
        "  else:\n",
        "    f = url\n",
        "  img = PIL.Image.open(f)\n",
        "  if max_size is not None:\n",
        "    img.thumbnail((max_size, max_size), PIL.Image.ANTIALIAS)\n",
        "  if mode is not None:\n",
        "    img = img.convert(mode)\n",
        "  img = np.float32(img)/255.0\n",
        "  return img\n",
        "\n",
        "def np2pil(a):\n",
        "  if a.dtype in [np.float32, np.float64]:\n",
        "    a = np.uint8(np.clip(a, 0, 1)*255)\n",
        "  return PIL.Image.fromarray(a)\n",
        "\n",
        "def imwrite(f, a, fmt=None):\n",
        "  a = np.asarray(a)\n",
        "  if isinstance(f, str):\n",
        "    fmt = f.rsplit('.', 1)[-1].lower()\n",
        "    if fmt == 'jpg':\n",
        "      fmt = 'jpeg'\n",
        "    f = open(f, 'wb')\n",
        "  np2pil(a).save(f, fmt, quality=95)\n",
        "\n",
        "def imencode(a, fmt='jpeg'):\n",
        "  a = np.asarray(a)\n",
        "  if len(a.shape) == 3 and a.shape[-1] == 4:\n",
        "    fmt = 'png'\n",
        "  f = io.BytesIO()\n",
        "  imwrite(f, a, fmt)\n",
        "  return f.getvalue()\n",
        "\n",
        "def im2url(a, fmt='jpeg'):\n",
        "  encoded = imencode(a, fmt)\n",
        "  base64_byte_string = base64.b64encode(encoded).decode('ascii')\n",
        "  return 'data:image/' + fmt.upper() + ';base64,' + base64_byte_string\n",
        "\n",
        "def imshow(a, fmt='jpeg'):\n",
        "  display(Image(data=imencode(a, fmt)))\n",
        "\n",
        "def tile2d(a, w=None):\n",
        "  a = np.asarray(a)\n",
        "  if w is None:\n",
        "    w = int(np.ceil(np.sqrt(len(a))))\n",
        "  th, tw = a.shape[1:3]\n",
        "  pad = (w-len(a))%w\n",
        "  a = np.pad(a, [(0, pad)]+[(0, 0)]*(a.ndim-1), 'constant')\n",
        "  h = len(a)//w\n",
        "  a = a.reshape([h, w]+list(a.shape[1:]))\n",
        "  a = np.rollaxis(a, 2, 1).reshape([th*h, tw*w]+list(a.shape[4:]))\n",
        "  return a\n",
        "\n",
        "def zoom(img, scale=4):\n",
        "  img = np.repeat(img, scale, 0)\n",
        "  img = np.repeat(img, scale, 1)\n",
        "  return img\n",
        "\n",
        "class VideoWriter:\n",
        "  def __init__(self, filename='_autoplay.mp4', fps=30.0, **kw):\n",
        "    self.writer = None\n",
        "    self.params = dict(filename=filename, fps=fps, **kw)\n",
        "\n",
        "  def add(self, img):\n",
        "    img = np.asarray(img)\n",
        "    if self.writer is None:\n",
        "      h, w = img.shape[:2]\n",
        "      self.writer = FFMPEG_VideoWriter(size=(w, h), **self.params)\n",
        "    if img.dtype in [np.float32, np.float64]:\n",
        "      img = np.uint8(img.clip(0, 1)*255)\n",
        "    if len(img.shape) == 2:\n",
        "      img = np.repeat(img[..., None], 3, -1)\n",
        "    self.writer.write_frame(img)\n",
        "\n",
        "  def close(self):\n",
        "    if self.writer:\n",
        "      self.writer.close()\n",
        "\n",
        "  def __enter__(self):\n",
        "    return self\n",
        "\n",
        "  def __exit__(self, *kw):\n",
        "    self.close()\n",
        "    if self.params['filename'] == '_autoplay.mp4':\n",
        "      self.show()\n",
        "\n",
        "  def show(self, **kw):\n",
        "      self.close()\n",
        "      fn = self.params['filename']\n",
        "      display(mvp.ipython_display(fn, **kw))\n",
        "\n",
        "#!nvidia-smi -L\n",
        "\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') \u003e= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QTsW1VdPnY22"
      },
      "outputs": [],
      "source": [
        "!pip install einops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C1hkDT38hSaP"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torchvision.models as models\n",
        "\n",
        "from functools import partial\n",
        "\n",
        "from einops import rearrange\n",
        "\n",
        "torch.set_default_tensor_type('torch.cuda.FloatTensor')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_5FEbeJ05ofv"
      },
      "outputs": [],
      "source": [
        "ident = torch.tensor([[0.0,0.0,0.0],[0.0,1.0,0.0],[0.0,0.0,0.0]])\n",
        "sobel_x = torch.tensor([[-1.0,0.0,1.0],[-2.0,0.0,2.0],[-1.0,0.0,1.0]])\n",
        "lap = torch.tensor([[1.0,2.0,1.0],[2.0,-12.0,2.0],[1.0,2.0,1.0]])\n",
        "lap6 = torch.tensor([[0.0,2.0,2.0],[2.0,-12.0,2.0],[2.0,2.0,0.0]])\n",
        "gauss = torch.tensor([[1.0,2.0,1.0],[2.0,4.0,2.0],[1.0,2.0,1.0]])/16.0\n",
        "\n",
        "def perchannel_conv(x, filters):\n",
        "  '''filters: [filter_n, h, w]'''\n",
        "  b, ch, h, w = x.shape\n",
        "  y = x.reshape(b*ch, 1, h, w)\n",
        "  y = F.pad(y, [1, 1, 1, 1], 'circular')\n",
        "  y = F.conv2d(y, filters[:,None])\n",
        "  return y.reshape(b, -1, h, w)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Czlr4NVm3XJD"
      },
      "source": [
        "# Models legend\n",
        "\n",
        "Select the model of interest from the list below.\n",
        "\n",
        "*   laplacian: Isotropic NCA model.\n",
        "*   lap6: Istropic NCA, (trained and/or evaluated) on an hexagonal grid.\n",
        "*   lap_gradnorm: Isotropic NCA variant discussed in the blogpost.\n",
        "*   steerable: Angle-based Steerable NCA.\n",
        "*   gradient: Gradient-based Steerable NCA.\n",
        "*   steerable_nolap: Angle-based Sterable NCA ablation without the laplacian filter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rMqvVwYi6Od4"
      },
      "outputs": [],
      "source": [
        "#@title Minimalistic Neural {vertical-output: true, run: \"auto\"}\n",
        "\n",
        "model_type = \"steerable_nolap\" #@param ['laplacian', 'lap6', 'lap_gradnorm', 'steerable', 'gradient', 'steerable_nolap']\n",
        "\n",
        "ANGLE_CHN = 0\n",
        "nhood_kernel = (lap != 0.0).to(torch.float32)\n",
        "if model_type == 'steerable':\n",
        "  ANGLE_CHN = 1  # last state channel is angle and should be treated\n",
        "                 # differently\n",
        "  def perception(state):\n",
        "    state, angle = state[:,:-1], state[:,-1:]\n",
        "    c, s = angle.cos(), angle.sin()\n",
        "    \n",
        "    # cells can also feel the average direction of their neightbours\n",
        "    #alpha = state[:,3:4].clip(0.0, 1.0)\n",
        "    #dir = torch.cat([c, s], 1)*alpha  # only \n",
        "    #avg_dir = perchannel_conv(dir, gauss[None,:])\n",
        "\n",
        "    grad = perchannel_conv(state, torch.stack([sobel_x, sobel_x.T]))\n",
        "    #grad = torch.cat([grad, avg_dir], 1)\n",
        "    # transform percieved vectors into local coords\n",
        "    gx, gy = grad[:,::2], grad[:,1::2]\n",
        "    rot_grad = torch.cat([gx*c+gy*s, gy*c-gx*s], 1)\n",
        "    state_lap = perchannel_conv(state, lap[None,:])\n",
        "    return torch.cat([state, rot_grad, state_lap], 1)\n",
        "\n",
        "elif model_type == 'steerable_nolap':\n",
        "  ANGLE_CHN = 1  # last state channel is angle and should be treated\n",
        "                 # differently\n",
        "  def perception(state):\n",
        "    state, angle = state[:,:-1], state[:,-1:]\n",
        "    c, s = angle.cos(), angle.sin()\n",
        "    \n",
        "    # cells can also feel the average direction of their neightbours\n",
        "    #alpha = state[:,3:4].clip(0.0, 1.0)\n",
        "    #dir = torch.cat([c, s], 1)*alpha  # only \n",
        "    #avg_dir = perchannel_conv(dir, gauss[None,:])\n",
        "\n",
        "    grad = perchannel_conv(state, torch.stack([sobel_x, sobel_x.T]))\n",
        "    #grad = torch.cat([grad, avg_dir], 1)\n",
        "    # transform percieved vectors into local coords\n",
        "    gx, gy = grad[:,::2], grad[:,1::2]\n",
        "    rot_grad = torch.cat([gx*c+gy*s, gy*c-gx*s], 1)\n",
        "    return torch.cat([state, rot_grad], 1)\n",
        "\n",
        "elif model_type == 'gradient':\n",
        "  def perception(state):\n",
        "    grad = perchannel_conv(state, torch.stack([sobel_x, sobel_x.T]))\n",
        "    # gradient of the last channel determines the cell direction\n",
        "    grad, dir = grad[:,:-2], grad[:,-2:]\n",
        "    dir = dir/dir.norm(dim=1, keepdim=True).clip(1.0)\n",
        "    c, s = dir[:,:1], dir[:,1:2]\n",
        "    # transform percieved vectors into local coords\n",
        "    gx, gy = grad[:,::2], grad[:,1::2]\n",
        "    rot_grad = torch.cat([gx*c+gy*s, gy*c-gx*s], 1)\n",
        "    state_lap = perchannel_conv(state, lap[None,:])\n",
        "    return torch.cat([state, state_lap, rot_grad], 1)\n",
        "\n",
        "elif model_type == 'lap_gradnorm':\n",
        "  def perception(state):\n",
        "    grad = perchannel_conv(state, torch.stack([sobel_x, sobel_x.T]))\n",
        "    gx, gy = grad[:,::2], grad[:,1::2]\n",
        "    state_lap = perchannel_conv(state, lap[None,:])\n",
        "    return torch.cat([state, state_lap, (gx*gx+gy*gy+1e-8).sqrt()], 1)\n",
        "\n",
        "elif model_type == 'laplacian':\n",
        "  def perception(state):\n",
        "    state_lap = perchannel_conv(state, lap[None,:])\n",
        "    return torch.cat([state, state_lap], 1)\n",
        "\n",
        "# add norm of gradients\n",
        "\n",
        "elif model_type == 'lap6':\n",
        "  nhood_kernel = (lap6 != 0.0).to(torch.float32)\n",
        "  def perception(state):\n",
        "    state_lap = perchannel_conv(state, lap6[None,:])\n",
        "    return torch.cat([state, state_lap], 1)\n",
        "\n",
        "else:\n",
        "  assert False, \"unknown model_type\"\n",
        "\n",
        "\n",
        "CHN = 16\n",
        "SCALAR_CHN = CHN-ANGLE_CHN\n",
        "\n",
        "# if you want to try experiments with synchronous NCA, you can set the value \n",
        "# below to 1.0\n",
        "DEFAULT_UPDATE_RATE = 0.5\n",
        "\n",
        "def get_alive_mask(x):\n",
        "  mature = (x[:,3:4]\u003e0.1).to(torch.float32)\n",
        "  return perchannel_conv(mature, nhood_kernel[None,:])\u003e0.5\n",
        "\n",
        "class CA(torch.nn.Module):\n",
        "  def __init__(self, chn=CHN, hidden_n=128):\n",
        "    super().__init__()\n",
        "    self.chn = chn\n",
        "    # determene the number of perceived channels\n",
        "    perc_n = perception(torch.zeros([1, chn, 8, 8])).shape[1]\n",
        "    # approximately equalize the param number btw model variants\n",
        "    hidden_n = 8*1024//(perc_n+chn)\n",
        "    hidden_n = (hidden_n+31)//32*32\n",
        "    print('perc_n:', perc_n, 'hidden_n:', hidden_n)\n",
        "\n",
        "    self.w1 = torch.nn.Conv2d(perc_n, hidden_n, 1)\n",
        "    self.w2 = torch.nn.Conv2d(hidden_n, chn, 1, bias=False)\n",
        "    self.w2.weight.data.zero_()\n",
        "\n",
        "  def forward(self, x, update_rate=DEFAULT_UPDATE_RATE):\n",
        "    alive = get_alive_mask(x)\n",
        "    y = perception(x)\n",
        "    y = self.w2(torch.relu(self.w1(y)))\n",
        "    b, c, h, w = y.shape\n",
        "    update_mask = (torch.rand(b, 1, h, w)+update_rate).floor()\n",
        "    x = x + y*update_mask\n",
        "    if SCALAR_CHN==CHN:\n",
        "      x = x*alive\n",
        "    else:\n",
        "      x = torch.cat([x[:,:SCALAR_CHN]*alive, x[:,SCALAR_CHN:]%(np.pi*2.0)], 1)\n",
        "    return x\n",
        "\n",
        "  def seed(self, n, sz=128, angle=None, seed_size=1):\n",
        "    x = torch.zeros(n, self.chn, sz, sz)\n",
        "    if SCALAR_CHN != CHN:\n",
        "      x[:,-1] = torch.rand(n, sz, sz)*np.pi*2.0\n",
        "    r, s = sz//2, seed_size\n",
        "    x[:,3:SCALAR_CHN,r:r+s, r:r+s] = 1.0\n",
        "    if angle is not None:\n",
        "      x[:,-1,r:r+s, r:r+s] = angle\n",
        "    return x\n",
        "\n",
        "def to_rgb(x):\n",
        "  rgb, a = x[:,:3], x[:,3:4]\n",
        "  return 1.0-a+rgb\n",
        "\n",
        "param_n = sum(p.numel() for p in CA().parameters())\n",
        "print('CA param count:', param_n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nH_veU6fwJKB"
      },
      "outputs": [],
      "source": [
        "\n",
        "def make_concentric_discrete(h, w, n):\n",
        "  # reference https://kazemnejad.com/blog/transformer_architecture_positional_encoding/\n",
        "  x = np.linspace(-1.0, 1.0, w)[None, :]\n",
        "  y = np.linspace(-1.0, 1.0, h)[:, None]\n",
        "  center = np.zeros([2,1,1])\n",
        "  #r = np.array([0.8])[:,None]\n",
        "  x, y = (x-center[0]), (y-center[1])\n",
        "  act = np.sin if n % 2 == 0 else np.cos\n",
        "  mask = np.sign(act(np.sqrt(x*x+y*y)*n*np.pi))\n",
        "  return mask.astype(np.float32) * 0.5\n",
        "\n",
        "def make_concentric(h, w, n):\n",
        "  # version with blurriness\n",
        "  # reference https://kazemnejad.com/blog/transformer_architecture_positional_encoding/\n",
        "  x = np.linspace(-1.0, 1.0, w)[None, :]\n",
        "  y = np.linspace(-1.0, 1.0, h)[:, None]\n",
        "  center = np.zeros([2,1,1])\n",
        "  #r = np.array([0.8])[:,None]\n",
        "  x, y = (x-center[0]), (y-center[1])\n",
        "  grad_start = 0.2\n",
        "  act = np.sin if n % 2 == 0 else np.cos\n",
        "  period = act(np.sqrt(x*x+y*y)*n*np.pi)\n",
        "  grad = (np.abs(period) \u003c grad_start).astype(np.float32)\n",
        "  mask = np.sign(period) * (1-grad) + period  *grad / grad_start\n",
        "  return mask.astype(np.float32) * 0.5\n",
        "\n",
        "H = W = 48\n",
        "\n",
        "mask = make_concentric(H, W, 1)\n",
        "imshow(mask+0.5)\n",
        "\n",
        "mask = make_concentric(H, W, 2)\n",
        "imshow(mask+0.5)\n",
        "\n",
        "mask = make_concentric(H, W, 3)\n",
        "imshow(mask+0.5)\n",
        "\n",
        "mask = make_concentric(H, W, 4)\n",
        "imshow(mask+0.5)\n",
        "#imshow(aux_target[1].cpu()/2.0+0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w8jq7yHqdwl7"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Not used currently, since we only need to make one stripe.\n",
        "def make_stripes(h, w, n):\n",
        "  x = np.linspace(-1.0, 1.0, w)[None, :]\n",
        "  y = np.linspace(-1.0, 1.0, h)[:, None]\n",
        "  center = np.zeros([2,1,1])\n",
        "  #r = np.array([0.8])[:,None]\n",
        "  x, y = (x-center[0])*np.ones_like(y), (y-center[1])*np.ones_like(x)\n",
        "  act = np.sin if n % 2 == 0 else np.cos\n",
        "  grad_start = 0.2\n",
        "  x_period = act(x*n*np.pi)\n",
        "  x_grad = (np.abs(x_period) \u003c grad_start).astype(np.float32)\n",
        "  x_mask = np.sign(x_period) * (1-x_grad) + x_period *x_grad / grad_start\n",
        "  y_period = act(y*n*np.pi)\n",
        "  y_grad = (np.abs(y_period) \u003c grad_start).astype(np.float32)\n",
        "  y_mask = np.sign(y_period) * (1-y_grad) + y_period  *y_grad / grad_start\n",
        "  return x_mask.astype(np.float32) * 0.5, y_mask.astype(np.float32) * 0.5\n",
        "\n",
        "H = W = 48\n",
        "\n",
        "x_mask, y_mask = make_stripes(H, W, 1)\n",
        "imshow(x_mask+0.5)\n",
        "imshow(y_mask+0.5)\n",
        "\n",
        "x_mask, y_mask = make_stripes(H, W, 2)\n",
        "imshow(x_mask+0.5)\n",
        "imshow(y_mask+0.5)\n",
        "\n",
        "x_mask, y_mask = make_stripes(H, W, 3)\n",
        "imshow(x_mask+0.5)\n",
        "imshow(y_mask+0.5)\n",
        "\n",
        "x_mask, y_mask = make_stripes(H, W, 4)\n",
        "imshow(x_mask+0.5)\n",
        "imshow(y_mask+0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgbEaZ3jp__K"
      },
      "source": [
        "# Aux L Type legend\n",
        "\n",
        "What kind of auxiliary channels are going to be present in the target image:\n",
        "\n",
        "*   noaux: No auxiliary channels. The 'spiderweb' target was trained with it.\n",
        "*   binary: One stripe mask as auxiliary channel. The 'lizard' target was trained with it.\n",
        "*   minimal: binary + a concentric auxiliary channel. The 'heart' target was trained with it.\n",
        "*   extended: more stripe and concentric modes for auxiliary channels. Not used in any publication.\n",
        "\n",
        "Select the target image and what auxiliary channels are of interest below.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZLj8FlkXDeFk"
      },
      "outputs": [],
      "source": [
        "\n",
        "TARGET_P = \"lizard\" #@param ['circle','lizard', 'heart', 'smiley', 'lollipop', 'unicorn', 'spiderweb']\n",
        "AUX_L_TYPE = \"binary\" #@param ['noaux', 'binary', 'minimal', 'extended']\n",
        "\n",
        "if  TARGET_P == 'circle':\n",
        "  def make_circle(h, w):\n",
        "    x = np.linspace(-1.0, 1.0, w)[None, :]\n",
        "    y = np.linspace(-1.0, 1.0, h)[:, None]\n",
        "    center = np.zeros([2,1,1])\n",
        "    r = np.array([0.9])[:,None]\n",
        "    x, y = (x-center[0])/r, (y-center[1])/r\n",
        "    mask = (x*x+y*y \u003c 1.0).astype(np.float32)\n",
        "    return mask\n",
        "\n",
        "  H = W = 48\n",
        "  mask = make_circle(H, W)\n",
        "  IS_COLORED = False\n",
        "  if IS_COLORED:\n",
        "    r = np.linspace(0,1,H)[:,None]*mask\n",
        "    g = np.linspace(0,1,W)[None,:]*mask\n",
        "  else:\n",
        "    r = g = np.zeros(mask.shape)\n",
        "  target_colors = np.stack([r, g, np.zeros(mask.shape)], -1)\n",
        "  #target = np.zeros([H, W, 4], dtype=np.float32)\n",
        "\n",
        "  #target[..., 3] = mask\n",
        "\n",
        "  target = np.concatenate([target_colors, mask[...,None]],-1).astype(np.float32)\n",
        "  imshow(target)\n",
        "  target[:,:,:3] *= target[:,:,3:]\n",
        "else:\n",
        "  emoji = {'lizard': '🦎',\n",
        "           'heart': '❤️',\n",
        "           'smiley': '😁',\n",
        "           'lollipop': '🍭',\n",
        "           'unicorn': '🦄', # overfits to the grid\n",
        "           'spiderweb': '🕸️'\n",
        "           }[TARGET_P][0]\n",
        "  \n",
        "  code = hex(ord(emoji))[2:].lower()\n",
        "  url = 'https://github.com/googlefonts/noto-emoji/blob/main/png/128/emoji_u%s.png?raw=true'%code\n",
        "  target = imread(url, 48)\n",
        "  imshow(target)\n",
        "  target[:,:,:3] *= target[:,:,3:]\n",
        "\n",
        "p = 12\n",
        "#target = F.pad(torch.tensor(target).permute(2, 0, 1), [p, p, p, p, 0, 2])\n",
        "target = F.pad(torch.tensor(target).permute(2, 0, 1), [p, p, p, p, 0, 0])\n",
        "W = target.shape[1]\n",
        "\n",
        "Wp = Hp = target.shape[1]\n",
        "if AUX_L_TYPE != 'noaux':\n",
        "  aux_target_l = []\n",
        "  #x_mask, y_mask = make_stripes(Hp, Wp, 2)\n",
        "  #aux_target_l += [torch.tensor(x_mask), torch.tensor(y_mask)]\n",
        "  #x_mask, y_mask = make_stripes(Hp, Wp, 2)\n",
        "  #aux_target_l += [torch.tensor(y_mask)]\n",
        "\n",
        "  print(target[3:].shape)\n",
        "  y_mask = torch.linspace(-1,1,W)[:,None].sign()*target[3]*0.5\n",
        "  aux_target_l += [y_mask]\n",
        "\n",
        "\n",
        "  if AUX_L_TYPE == \"extended\":\n",
        "    x_mask = torch.linspace(-1,1,W)[None,:].sign()*target[3]*0.5\n",
        "    aux_target_l += [torch.tensor(x_mask)]\n",
        "    aux_target_l += [torch.tensor(make_concentric(Hp, Wp, 2)),\n",
        "                    torch.tensor(make_concentric(Hp, Wp, 3)),\n",
        "                    torch.tensor(make_concentric(Hp, Wp, 4))]\n",
        "  if AUX_L_TYPE == \"minimal\":\n",
        "    aux_target_l += [torch.tensor(make_concentric(Hp, Wp, 4))]\n",
        "  aux_target = torch.stack(aux_target_l)*target[3:4]\n",
        "\n",
        "  imshow(aux_target[0].cpu()+0.5)\n",
        "\n",
        "  for at in aux_target:\n",
        "    imshow((1. - target[3] + target[3]*(at+0.5)).cpu())\n",
        "\n",
        "  print(target.shape, aux_target.shape)\n",
        "  target = torch.cat([target, aux_target])\n",
        "\n",
        "model_suffix = model_type + \"_\" + TARGET_P + \"_\" + AUX_L_TYPE\n",
        "print(model_suffix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YDE6iwRWebeP"
      },
      "outputs": [],
      "source": [
        "from torchvision.transforms.functional_tensor import gaussian_blur\n",
        "def sharpen_filter(img):\n",
        "  blured = gaussian_blur(img, [5, 5], [1, 1])\n",
        "  return img + (img-blured)*2.0\n",
        "\n",
        "\n",
        "# separating the logic, since xy_grid is not inherent of the Loss.\n",
        "hex_grid = model_type == 'lap6'\n",
        "if hex_grid:\n",
        "  s = np.sqrt(3)/2.0\n",
        "  hex2xy = np.float32([[1.0, 0.0], \n",
        "                      [0.5, s]])\n",
        "  xy2hex = torch.tensor(np.linalg.inv(hex2xy))\n",
        "\n",
        "  x = torch.linspace(-1, 1, W)\n",
        "  y, x = torch.meshgrid(x, x)\n",
        "  xy_grid = torch.stack([x, y], -1)\n",
        "  # This grid will be needed later on, in the step functions.\n",
        "  xy_grid = (xy_grid@xy2hex+1.0)%2.0-1.0\n",
        "\n",
        "class InvariantLoss:\n",
        "  def __init__(self, target, mirror=False, sharpen=True, hex_grid=False):\n",
        "    self.sharpen = sharpen\n",
        "    self.mirror = mirror\n",
        "    self.channel_n = target.shape[0]\n",
        "    W = target.shape[-1]\n",
        "    self.r = r = torch.linspace(0.5/W, 1, W//2)[:,None]\n",
        "    self.angle = a = torch.range(0, W*np.pi)/(W/2)\n",
        "    self.polar_xy = torch.stack([r*a.cos(), r*a.sin()], -1)[None,:]\n",
        "    if hex_grid:\n",
        "      self.polar_xy = (self.polar_xy@xy2hex+1.0)%2.0-1.0\n",
        "\n",
        "      # also make an x\n",
        "    target = target[None,:]\n",
        "    if self.sharpen:\n",
        "      target = sharpen_filter(target)\n",
        "    self.polar_target = F.grid_sample(target, self.polar_xy)\n",
        "    self.fft_target = torch.fft.rfft(self.polar_target).conj()\n",
        "    self.polar_target_sqnorm = self.polar_target.square().sum(-1, keepdim=True)\n",
        "\n",
        "  def calc_losses(self, batch, extra_outputs=False):\n",
        "    batch = batch[:, :self.channel_n]\n",
        "    if self.sharpen:\n",
        "      batch = sharpen_filter(batch)\n",
        "    polar_batch = F.grid_sample(batch, self.polar_xy.repeat(len(batch), 1, 1, 1))\n",
        "    X = torch.fft.rfft(polar_batch)\n",
        "    n = polar_batch.shape[-1]\n",
        "    xy = torch.fft.irfft(X*self.fft_target, n)\n",
        "    if self.mirror:\n",
        "      xy = torch.cat([xy, torch.fft.irfft(X*self.fft_target.conj(), n)], -1)\n",
        "    xx = polar_batch.square().sum(-1, keepdim=True)\n",
        "    yy = self.polar_target_sqnorm\n",
        "    sqdiff = (xx+yy-2.0*xy)\n",
        "    losses = sqdiff.mean([1, 2])\n",
        "    if extra_outputs:\n",
        "      return losses, batch, polar_batch\n",
        "    else:\n",
        "      return losses\n",
        "\n",
        "  def __call__(self, batch):\n",
        "    return self.calc_losses(batch).min(-1)[0].mean()\n",
        "\n",
        "  def plot_losses(self, x):\n",
        "    losses = self.calc_losses(x[None,:])[0].cpu()\n",
        "    fig = pl.figure(figsize=(10, 10))\n",
        "    ax0 = fig.add_subplot(111)\n",
        "    vis = to_rgb(x[None,:4])[0].permute(1, 2, 0).cpu().clip(0, 1)\n",
        "    ax0.imshow(vis, alpha=0.5)\n",
        "    ax0.axis(\"off\")\n",
        "    ax = fig.add_subplot(111, polar=True, label='polar')\n",
        "    ax.set_theta_zero_location('N')\n",
        "    ax.set_theta_direction(-1)\n",
        "    ax.set_facecolor(\"None\")\n",
        "    ang = self.angle.cpu()\n",
        "    if not self.mirror:\n",
        "      ax.plot(ang, losses, linewidth=3.0)\n",
        "    else:\n",
        "      ax.plot(ang, losses[:len(ang)], linewidth=3.0)\n",
        "      ax.plot(ang, losses[len(ang):], linewidth=3.0)\n",
        "    min_i = losses.argmin()\n",
        "    pl.plot(ang[min_i%len(ang)], losses[min_i], 'or', markersize=12)\n",
        "\n",
        "\n",
        "mirror = model_type in ['gradnorm','laplacian','lap6']\n",
        "target_loss_f = InvariantLoss(target, mirror=mirror, hex_grid=hex_grid)\n",
        "vis = to_rgb(target_loss_f.polar_target)[0].permute(1, 2, 0).cpu()\n",
        "imshow(zoom(vis))\n",
        "\n",
        "target_loss_f.plot_losses(target)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Cd1uMD3cZw3"
      },
      "outputs": [],
      "source": [
        "#@title setup training\n",
        "ca = CA() \n",
        "loss_log = []\n",
        "with torch.no_grad():\n",
        "  pool = ca.seed(256, W)\n",
        "opt = torch.optim.Adam(ca.parameters(), 1e-3)\n",
        "#lr_sched = torch.optim.lr_scheduler.MultiStepLR(opt, [1000, 3000, 20000], 0.3)\n",
        "# for the experiment with auxiliary loss\n",
        "#lr_sched = torch.optim.lr_scheduler.MultiStepLR(opt, [3000, 10000], 0.3)\n",
        "lr_sched = torch.optim.lr_scheduler.CyclicLR(\n",
        "    opt, 1e-5, 1e-3, step_size_up=2000, mode='triangular2', cycle_momentum=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3pxjdESnYlIC"
      },
      "outputs": [],
      "source": [
        "#@title training loop {vertical-output: true}\n",
        "def make_circle_masks(n, h, w):\n",
        "  x = np.linspace(-1.0, 1.0, w)[None, None, :]\n",
        "  y = np.linspace(-1.0, 1.0, h)[None, :, None]\n",
        "  center = np.random.uniform(-0.5, 0.5, [2, n, 1, 1])\n",
        "  r = np.random.uniform(0.1, 0.4, [n, 1, 1])\n",
        "  x, y = (x-center[0])/r, (y-center[1])/r\n",
        "  mask = (x*x+y*y \u003c 1.0).astype(np.float32)\n",
        "  return mask\n",
        "\n",
        "\n",
        "for i in range(50000):\n",
        "  with torch.no_grad():\n",
        "    batch_idx = np.random.choice(len(pool), 8, replace=False)\n",
        "    x = pool[batch_idx]\n",
        "\n",
        "    if len(loss_log) \u003c 4000:\n",
        "      seed_rate = 1\n",
        "    else:\n",
        "      # exp because of decrease of step_n\n",
        "      #seed_rate = 3\n",
        "      seed_rate = 6\n",
        "    if i%seed_rate==0:\n",
        "      x[:1] = ca.seed(1, W)\n",
        "      \n",
        "    #damage_rate = 3 # for spiderweb and heart\n",
        "    damage_rate = 6  # for lizard?\n",
        "    if i%damage_rate==0:\n",
        "      mask = torch.from_numpy(make_circle_masks(1, W, W)[:,None]).to(\"cuda\")\n",
        "      if hex_grid:\n",
        "        mask = F.grid_sample(mask, xy_grid[None,:].repeat([len(mask), 1, 1, 1]), mode='bicubic')\n",
        "\n",
        "      x[-1:] *= (1.0 - mask)\n",
        "  \n",
        "    # EXTRA:\n",
        "    # if all the cells have died, reset the sample.\n",
        "    if len(loss_log) % 10 == 0:\n",
        "      all_cells_dead_mask = (torch.sum(x[1:, 3:4],(1,2,3)) \u003c 1e-6).float()[:,None,None,None]\n",
        "      if all_cells_dead_mask.sum() \u003e 1e-6:\n",
        "        print(\"got here.\")\n",
        "        x[1:] = all_cells_dead_mask * ca.seed(7, W) + (1. - all_cells_dead_mask) * x[1:]\n",
        "\n",
        "\n",
        "  #step_n = np.random.randint(32, 128)\n",
        "  # new!  \n",
        "  # everything worked but the unicorn pattern was constantly imploding with this.\n",
        "  #step_n = np.random.randint(96, 128)\n",
        "  step_n = np.random.randint(64, 96)\n",
        "  overflow_loss = 0.0\n",
        "  diff_loss = 0.0\n",
        "  target_loss = 0.0\n",
        "  for k in range(step_n):\n",
        "    px = x\n",
        "    x = ca(x)\n",
        "    diff_loss += (x-px).abs().mean()\n",
        "    overflow_loss += (x-x.clamp(-2.0, 2.0))[:,:SCALAR_CHN].square().sum()\n",
        "\n",
        "    # experimenting to address implosions:\n",
        "    if k == 0:\n",
        "      target_loss += target_loss_f(x[:,:target.shape[0]])\n",
        "      \"\"\"\n",
        "      if AUX_L_TYPE != \"noaux\":\n",
        "        aux_target_loss += aux_target_loss_f(\n",
        "            x[:,4:4+aux_target.shape[-3]]) * 2e-1\n",
        "      \"\"\"\n",
        "\n",
        "  target_loss += target_loss_f(x[:,:target.shape[0]])\n",
        "  \"\"\"\n",
        "  if AUX_L_TYPE != \"noaux\":\n",
        "    aux_target_loss += aux_target_loss_f(\n",
        "        x[:,4:4+aux_target.shape[-3]]) * 2e-1\n",
        "  \"\"\"\n",
        "  target_loss /= 2.\n",
        "  #aux_target_loss /= 2.\n",
        "  diff_loss = diff_loss*10.0\n",
        "  loss = target_loss+overflow_loss+diff_loss# + aux_target_loss\n",
        "\n",
        "  with torch.no_grad():\n",
        "    loss.backward()\n",
        "    for p in ca.parameters():\n",
        "      p.grad /= (p.grad.norm()+1e-8)   # normalize gradients \n",
        "    opt.step()\n",
        "    opt.zero_grad()\n",
        "    lr_sched.step()\n",
        "\n",
        "    pool[batch_idx] = x                # update pool\n",
        "    \n",
        "    loss_log.append(loss.item())\n",
        "    if i%32==0:\n",
        "      clear_output(True)\n",
        "      pl.plot(loss_log, '.', alpha=0.1)\n",
        "      pl.yscale('log')\n",
        "      pl.ylim(np.min(loss_log), loss_log[0])\n",
        "      pl.show()\n",
        "      imgs = to_rgb(x)\n",
        "      if hex_grid:\n",
        "        imgs = F.grid_sample(imgs, xy_grid[None,:].repeat([len(imgs), 1, 1, 1]), mode='bicubic')\n",
        "      imgs = imgs.permute([0, 2, 3, 1]).cpu()\n",
        "\n",
        "      imshow(zoom(tile2d(imgs, 4), 2))\n",
        "\n",
        "      if AUX_L_TYPE != \"noaux\":\n",
        "        alphas = x[:,3].cpu()\n",
        "        for extra_i in range(aux_target.shape[-3]):\n",
        "          imgs = 1. - alphas + alphas*(x[:,4+extra_i].cpu() + 0.5)\n",
        "\n",
        "          if hex_grid:\n",
        "            imgs = F.grid_sample(\n",
        "                imgs[:,None], xy_grid[None,:].repeat([len(imgs), 1, 1, 1]).cpu(), \n",
        "                mode='bicubic')[:,0]\n",
        "          imshow(zoom(tile2d(imgs, 8), 1))\n",
        "\n",
        "\n",
        "\n",
        "    if i%10 == 0:\n",
        "      print('\\rstep_n:', len(loss_log),\n",
        "        ' loss:', loss.item(), \n",
        "        ' lr:', lr_sched.get_lr()[0], end='')\n",
        "    if len(loss_log) % 500 == 0:\n",
        "      model_name = model_suffix + \"_{:07d}.pt\".format(len(loss_log))\n",
        "      print(model_name)\n",
        "      torch.save(ca.state_dict(), model_name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OXBxpbreYONj"
      },
      "outputs": [],
      "source": [
        "model_name = model_suffix + \"_{:07d}.pt\".format(len(loss_log))\n",
        "print(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hf8OBZ_kYFci"
      },
      "outputs": [],
      "source": [
        "# how to save a model\n",
        "torch.save(ca, model_name)\n",
        "from google.colab import files\n",
        "files.download(model_name) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yLqtVAf80pjS"
      },
      "outputs": [],
      "source": [
        "# how to save all checkpoints\n",
        "print(model_suffix)\n",
        "shell_command = f\"zip {model_suffix}.zip {model_suffix}_*\"\n",
        "!$shell_command\n",
        "from google.colab import files\n",
        "files.download(f\"{model_suffix}.zip\") "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PgULDG5NcGHS"
      },
      "outputs": [],
      "source": [
        "# optionally, load a model from a checkpoint.\n",
        "model_ckpt = \"FILL.pt\"\n",
        "ca = torch.load(model_ckpt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ppqq4Hsao65t"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "  x = ca.seed(8, 96)\n",
        "  #x = ca.seed(9, 72)\n",
        "  count = 0\n",
        "  for k in tnrange(300, leave=False): # was 1000\n",
        "    step_n = min(2**(k//30), 32)\n",
        "    for i in range(step_n):\n",
        "      x = ca(x)\n",
        "    count += step_n\n",
        "  print(count)\n",
        "\n",
        "  imgs = to_rgb(x)\n",
        "  if hex_grid:\n",
        "    imgs = F.grid_sample(imgs, xy_grid[None,:].repeat([len(imgs), 1, 1, 1]), mode='bicubic')\n",
        "  imgs = imgs.permute([0, 2, 3, 1]).cpu()\n",
        "\n",
        "  imshow(zoom(tile2d(imgs, 4), 2))\n",
        "\n",
        "  alphas = x[:,3].cpu()\n",
        "  for extra_i in range(aux_target.shape[-3]):\n",
        "    imgs = 1. - alphas + alphas*(x[:,4+extra_i].cpu() + 0.5)\n",
        "\n",
        "    if hex_grid:\n",
        "      imgs = F.grid_sample(\n",
        "          imgs[:,None], xy_grid[None,:].repeat([len(imgs), 1, 1, 1]).cpu(), \n",
        "          mode='bicubic')[:,0]\n",
        "    imshow(zoom(tile2d(imgs, 8), 1))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "012NXnM8kRDN"
      },
      "source": [
        "## Snapshot of a loss for an intermediate step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ICkZT9AFkYYQ"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "  x = ca.seed(1, 72)\n",
        "  count = 0\n",
        "  for k in tnrange(500, leave=False):\n",
        "    x = ca(x)\n",
        "\n",
        "  target_loss_f.plot_losses(x[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZTVkyfKc_2mF"
      },
      "outputs": [],
      "source": [
        "#@title Video: All in the same grid {vertical-output: true}\n",
        "with VideoWriter() as vid, torch.no_grad():\n",
        "  #x = ca.seed(1, 128)\n",
        "  sz = 256\n",
        "  x = torch.zeros([1, 16, sz, sz])\n",
        "  # this is with steerables!\n",
        "  if model_type in ['steerable', 'steerable_nolap']:\n",
        "    x[:,-1] = torch.rand(sz, sz)*(2.0*np.pi)\n",
        "  for i in range(5):\n",
        "    i, j = np.random.randint(sz-40, size=2)+20\n",
        "    x[:,3:SCALAR_CHN,i:i+1,j:j+1] = 1.0\n",
        "  count = 0\n",
        "  for k in tnrange(400, leave=False):\n",
        "    step_n = min(2**(k//30), 128)\n",
        "    for i in range(step_n):\n",
        "      x = ca(x)\n",
        "    count += step_n\n",
        "    img = to_rgb(x)[0].permute(1, 2, 0).cpu()\n",
        "    vid.add(zoom(img, 2))\n",
        "print(count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lKx2ij3-Bl4b"
      },
      "outputs": [],
      "source": [
        "#@title Video: different grids {vertical-output: true}\n",
        "eval_grid_size = 72\n",
        "#eval_grid_size = 96\n",
        "video_max_speed = 128\n",
        "#video_max_speed = 32\n",
        "# Long run\n",
        "# n_frames = 500\n",
        "# fast run\n",
        "n_frames = 300\n",
        "with VideoWriter() as vid, torch.no_grad():\n",
        "  #x = ca.seed(16, 96)\n",
        "  x = ca.seed(16, eval_grid_size)\n",
        "  count = 0\n",
        "  for k in tnrange(n_frames, leave=False): # was 1000\n",
        "    step_n = min(2**(k//30), video_max_speed)\n",
        "    for i in range(step_n):\n",
        "      x = ca(x)\n",
        "    count += step_n\n",
        "    img = to_rgb(x).permute(0, 2, 3, 1).cpu()\n",
        "    vid.add(zoom(tile2d(img), 2))\n",
        "print(count)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "private_outputs": true,
      "provenance": [
        {
          "file_id": "1jbcbI2fTknjVINSpI2VAhhzeQ2A1SQy6",
          "timestamp": 1676798240379
        },
        {
          "file_id": "17_q9499feZUH9njAhQgdeaokv2AlbjeK",
          "timestamp": 1667405450125
        },
        {
          "file_id": "1XIhd7YkQ0M6jlzLWRZmFUOFgwk3GMlSa",
          "timestamp": 1646255678994
        },
        {
          "file_id": "1DgqQVO-dsEnVzct-SnE2KRSuWDdG3znO",
          "timestamp": 1645958250519
        },
        {
          "file_id": "1Tt0jTsoRkLqV-s8uYBjI4RDid5DT_e9C",
          "timestamp": 1642686866102
        },
        {
          "file_id": "1b4SICkzaCkpGpFaiC8U7SVuPJq81CbPm",
          "timestamp": 1638196891769
        },
        {
          "file_id": "https://github.com/google-research/self-organising-systems/blob/master/notebooks/texture_nca_pytorch.ipynb",
          "timestamp": 1638193443717
        }
      ]
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
